\documentclass[aps,prl,reprint,toc]{revtex4-1}
% Engine-specific settings
% Detect pdftex/xetex/luatex, and load appropriate font packages.
% This is inspired by the approach in the iftex package.
% pdftex:
\ifx\pdfmatch\undefined
\else
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
\fi
% xetex:
\ifx\XeTeXinterchartoks\undefined
\else
    \usepackage{fontspec}
    \defaultfontfeatures{Ligatures=TeX}
\fi
% luatex:
\ifx\directlua\undefined
\else
    \usepackage{fontspec}
\fi
% End engine-specific settings
\usepackage[english]{babel}
\usepackage{csquotes}
% \usepackage[backend=biber, sortcites]{biblatex}
\usepackage{url}
\usepackage{textcomp}
\usepackage[usenames,dvipsnames,svgnames, table]{xcolor}
\usepackage[font={scriptsize}]{caption}
\usepackage{amsmath} \usepackage{amsthm} \usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{tikz} \usepackage{float}
\usepackage[procnames]{listings}
\usepackage{pstool} \usepackage{pgfplots}
\usepackage{wrapfig} \usepackage{graphicx} \usepackage{epstopdf}
\usepackage{afterpage}
\usepackage{physics}
\usepackage{multirow}
\usepackage{gensymb}
\usepackage{algorithm}
\usepackage{microtype}
\usepackage[noend]{algpseudocode}
\usepackage{xcolor,colortbl}
\usepackage{microtype}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage{pythontex}
% \usepackage{authblk}
\usepackage{nth}
\usepackage{siunitx}
% \usepackage[toc,page]{appendix}
\floatstyle{plaintop}
\restylefloat{table}

% SET LISTING STUFF (FRED)
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dred}{rgb}{0.545,0,0}
\definecolor{dblue}{rgb}{0,0,0.545}
\definecolor{lgrey}{rgb}{0.9,0.9,0.9}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\lstdefinelanguage{cpp}{
      backgroundcolor=\color{lgrey},
      basicstyle=\footnotesize \ttfamily \color{black} \bfseries,
      breakatwhitespace=false,
      breaklines=true,
      captionpos=b,
      commentstyle=\color{dkgreen},
      deletekeywords={...},
      escapeinside={\%*}{*)},
      frame=off,
      language=C++,
      keywordstyle=\color{purple},
      morekeywords={BRIEFDescriptorConfig,string,TiXmlNode,DetectorDescriptorConfigContainer,istringstream,cerr,exit},
      identifierstyle=\color{black},
      stringstyle=\color{blue},
      % numbers=left,
      % numbersep=5pt,
      numberstyle=\tiny\color{black},
      rulecolor=\color{black},
      showspaces=false,
      showstringspaces=false,
      showtabs=false,
      stepnumber=1,
      tabsize=5,
      title=\lstname,
    }

% Custom commands
\newcommand{\unit}[1]{\:\mathrm{#1}}
\newcommand{\noref}[1]{\hyperref[#1]{\ref*{#1}}}
\newcommand{\nonref}[1]{\hyperref[]{\ref*{#1}}}
\newcommand\blankpage{%
  \null
  \thispagestyle{empty}%
  \addtocounter{page}{-1}%
  \newpage}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{7} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{7}  % for normal

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\columnwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}


% Biber for references
% \addbibresource{references.bib}

\begin{document}
\sisetup{detect-all}
\title{Project 1}
\author{Erlend Lima}
\author{Frederik J. Mellbye}
\author{Aram Salihi}
\author{Halvard Sutterud}
\affiliation{University of Oslo, Oslo, Norway}
\date{\today}

\begin{abstract}
      In this project three methods of solving the one-dimensional Poisson equation with
      Dirchelet boundary conditions are investigated. The equation was discretized,
      and written as a system of linear equations. This equates to
      a tridiagonal matrix equation, which was solved using the general Thomas algorithm,
      a specialized version of the Thomas algorithm and by LU-decomposing the matrix. The
      numerical error is then analyzed for both methods, and the algorithm speeds are investigated and discussed.

      The specialization of the algorithm for our specific problem halved the
      amount of floating point operations. For large
      matrices ($n \sim 10^5$) the LU-decomposition requires
      more memory than what was available, which was not a problem with the Thomas
      algorithm. Also, the Thomas algorithm produced solutions with smaller errors
      than the LU method. Therefore the Thomas is deemed most suited for solving the problem
      examined in this paper.
\end{abstract}
\maketitle
\tableofcontents
\newpage
% \newpage
% \twocolumn[
% \begin{@twocolumnfalse}
%   \tableofcontents
% \end{@twocolumnfalse}
% ]

% % Get all of the data from the script into a dictionary
% \begin{pycode}
% from subprocess import Popen, PIPE
% from latextools import untag_all
% p = Popen(['python', '../analysis/analyze.py', '../cpp'],
% stdout=PIPE, stderr=PIPE)
% output, err = p.communicate()
% data = output.decode('utf8')
% latex_data = untag_all(data)
% \end{pycode}
%
% \begin{table}[ht]
%   \centering
%   \pyc{print(latex_data['error_table'])}
%   \caption{Summary of the errors}
%   \label{tab:error}
% \end{table}
%
% \begin{figure}[ht]
%   \centering
%   \includegraphics[scale=0.5]{figures/function.eps}
%   \caption{\label{fig:general} Caption}
% \end{figure}
\blankpage
\blankpage
\section{Introduction}
In this paper numerical solutions to the one-dimensional Poisson equation are
examined. Many important differential equations in science can be re-written  

\section{Theory}
\subsection{Discretizing the Poisson equation}
The one-dimensional Poisson equation with Dirchelet boundary conditions is
\begin{align*}
  \frac{d^2 u}{d x^2} = - f
\end{align*}
We can approximate the second derivative of $u(x)$ using a Taylor expansion
and solving for $\frac{d^2 u}{d x^2}$:
\begin{align*}
  \frac{d^2 u}{d x^2} \approx \frac{u(x+h) + u(x-h) - 2 u(x)}{h^2} + O(h^2)
\end{align*}
The equation is discretized with grid points $x_1, x_2, \hdots, x_{n}$. Imposing
Dirchelet boundary conditions forces $x_1 = x_n = 0$, using the handy notation
$u(x_i + h) = u_{i+1}$ and inserting the approximated second derivative into the
Poisson equation yields
\begin{align*}
  \frac{u_{i+1} + u_{i-1} - 2 u_i}{h^2} = -f_i
\end{align*}
where $h = \frac{1}{n+1}$ is the step size, i.e. the distance between grid points, and
$f_i = f(x_i)$. This discretized version of the one dimensional Poisson equation is
conveniently a linear system of equations, and can therefore be written
as the matrix equation
\begin{align*}
  A \mathbf{u} = h^2 \mathbf{f}
\end{align*}
where
\begin{align*}
  A =
  \begin{bmatrix}
    2 & -1 & 0  & \hdots & \hdots &   0    \\
    -1 & 2 & -1 & 0      & &\vdots \\
    0 & -1 & 2  & -1     & 0 &  \\
    \vdots & 0 & -1  & 2     & -1 & 0 \\
    & & \ddots & \ddots & \ddots & \vdots\\
    0 & \hdots  &\hdots & 0 &-1 & 2 \\
\end{bmatrix}
\end{align*}
is a $n \times n$ tridiagonal matrix, the only non-zero elements are on,
directly above or directly below the diagonal. Row reducing the matrix can therefore
be done in an efficient way using the Thomas algorithm, as we shall see in the next paragraph.
\subsection{Solving a general tridiagonal matrix problem}
A general tridiagonal matrix equation is on the form
\begin{align*}
  \begin{bmatrix}
    b_1 & c_1 & 0  & \hdots & \hdots &   0    \\
    a_2 & b_2 & c_2 & 0      & &\vdots \\
    0 & a_3 & b_3  & c_3     & 0 &  \\
    \vdots & 0 & a_4  & b_4     & c_4 & 0 \\
    & & \ddots & \ddots & \ddots & \vdots\\
    0 & \hdots  &\hdots & 0 &a_n & b_n \\
  \end{bmatrix}
  \begin{bmatrix}
    u_1 \\ u_2 \\ u_3 \\ \vdots \\ \\ u_n
  \end{bmatrix}
  =
  \begin{bmatrix}
    v_1 \\ v_2 \\ v_3 \\ \vdots \\ \\ v_n
  \end{bmatrix}
\end{align*}
where $v_i = h^2 f_i$ in the case examined in this project. To get the matrix
in row reduced echelon form and solve the problem, the $a_i$'s are first eliminated
by Gaussian elimination.
First, $\frac{a_2}{b_1}$ times the first row is subtracted from the second.
This gives
\begin{align*}
  \begin{bmatrix}
    b_1 & c_1 & 0  & \hdots & \hdots &   0    \\
    0 & b'_2 & c_2 & 0      & &\vdots \\
    0 & a_3 & b_3  & c_3     & 0 &  \\
    \vdots & 0 & a_4  & b_4     & c_4 & 0 \\
    & & \ddots & \ddots & \ddots & \vdots\\
    0 & \hdots  &\hdots & 0 &a_n & b_n \\
  \end{bmatrix}
  \begin{bmatrix}
    u_1 \\ u_2 \\ u_3 \\ \vdots \\ \\ u_n
  \end{bmatrix}
  =
  \begin{bmatrix}
    v_1 \\ v'_2 \\ v_3 \\ \vdots \\ \\ v_n
  \end{bmatrix}
\end{align*}
where $b'_2 = b_2 - \frac{a_2}{b_1} c_1$ and $v'_2 = v_2 - \frac{a_2}{b_1}v_1$.
For the next row, exactly the same operation is used, but notice how the previous
elements $b'_2$ and $v'_2$ now have been updated in the last iteration. Generalizing this
argument for each row, a general expression for the diagonal elements is
\begin{align*}
  b'_i = b_i - \frac{a_i}{b'_{i-1}}c_{i-1}
\end{align*}
where $b'_1 = b_1$ and $i = 2,3,...,n$. Similarly, elements in the right-hand side vector
$\mathbf{v}'$ are modified to
\begin{align*}
  v'_{i} = v_i - \frac{a_i}{b'_{i-1}}v'_{i-1}
\end{align*}
where $v'_1 = v_1$ and $i = 2,\hdots,n$. After completing the forward substitution,
the matrix equation reads
\begin{align*}
  \begin{bmatrix}
    b'_1 & c_1 & 0  & \hdots & \hdots &   0    \\
    0 & b'_2 & c_2 & 0      & &\vdots \\
    0 & 0 & b'_3  & c_3     & 0 &  \\
    \vdots & 0 & 0  & b'_4     & c_4 & 0 \\
    & & \ddots & \ddots & \ddots & \vdots\\
    0 & \hdots  &\hdots & 0 &0 & b'_n \\
  \end{bmatrix}
  \begin{bmatrix}
    u_1 \\ u_2 \\ u_3 \\ \vdots \\ \\ u_n
  \end{bmatrix}
  =
  \begin{bmatrix}
    v'_1 \\ v'_2 \\ v'_3 \\ \vdots \\ \\ v'_n
  \end{bmatrix}
\end{align*}
By inspection, the solution for the final point $u_n$ is explicitly given by the
bottom row:
\begin{align*}
  b'_n u_n = v'_n \rightarrow u_n = \frac{v'_n}{b'_n}
\end{align*}
The rest of the solution $u(x_i)$ is then computed by backward substitution, given
$u_i$ one can compute $u_{i-1}$. For instance, row $n-1$ reads
\begin{align*}
  b'_{n-1} u_{n-1} + c_{n-1} u_n &= v'_{n-1} \\
  u_{n-1} &= \frac{v'_{n-1} - c_{n-1} u_n}{b'_{n-1}}
\end{align*}
In general then, the back substitution is done by
\begin{align*}
  u_i = \frac{v'_i - c_i u_{i+1}}{b'_i}
\end{align*}
where $i = n-1, n-2, \hdots, 1$.
\subsection{Optimizing the Thomas algorithm for a specific case}
In the case presented in this project, $a_i = c_i = -1$ and $b_i = 2$. The fact
that there are just two different values in the matrix greatly simplifies the
calculations, since all the calculations involving only $a_i$, $b_i$ and $c_i$
can be done beforehand. Also, it is possible to derive an analytic expression for
$b'_i$. This is given by
\begin{align*}
  b'_i = \frac{i+1}{i}
\end{align*}
and is found and proved by induction in appendix A?.

\subsection{Solving the general tridiagonal matrix problem by LU-decomposition}
Another way to solve matrix equations is LU-decomposing A, and then solving
two matrix equations. This is a frequently used method for solving more general
sets of linear equations. The LU-decomposition is a form of Gaussian elimination,
where A is factored into matrices L and U. L is lower triangular with 1 in each
element on the diagonal, and U is upper triangular. The matrix equation is
\begin{align*}
  A\mathbf{u} &= \mathbf{v} \\
  LU \mathbf{u} &= \mathbf{v}
\end{align*}
Introducing $\mathbf{y} = U\mathbf{u}$, the solution $\mathbf{u}$ can now be
computed in two steps. First, $\mathbf{y}$ is found by solving
\begin{align*}
  L\mathbf{y} = \mathbf{v}
\end{align*}
which is then inserted in LABEL
\begin{align*}
  U\mathbf{u} = \mathbf{y}
\end{align*}
and solved for $\mathbf{u}$.

\subsection{Counting the number of FLOPS for each method}
A simple way of determining the computational speed of an algorith is simply
counting the number of floating point operations. The fewer calculations the
computer has to make, the faster an algorithm will run. In this section approximate numbers
for the amount of floating point operations (flops) are determined.
\subsubsection{The general Thomas algorithm}
The general algorithm with arbitrary tridiagonal elements consists of two steps,
the forward substitution (two equations) and the backward substitution (one equation).
In the forward substitution, some of the operations can be precomputed. Since
$a_i$, $c_i$ is known for all $i$ considered, the product
$a_i c_{i-1}$ can be precomputed and does not provide any flops.
Therefore, computing a $b'_i$ requires only two operations, and
these are done $(n-1)$ times. Computing a $v'_i$ requires three flops, one
product, one division and an addition. These operations are also repeated $(n-1)$ times,
so the total amount of flops in the forward substitution is:
\begin{align*}
  2(n-1) + 3(n-1) = 5(n-1)
\end{align*}
In the backward substitution, no quantities can be precomputed as they are
produced by the algorithm itself. Counting the number of operatons yields $3(n-1)$ flops.
In total, then, the number of flops required in the general Thomas algorithm is
\begin{align*}
  \text{flops}_\text{Thomas} = 8(n-1)
\end{align*}
\subsubsection{The special case Thomas algorithm}
For the specialized algorithm, even more quantities can be precomuted and the
amount of flops can therefore be reduced further. First of all, an analytic
expression for $b'_i$, the diagonal elements, does not contribute with any flops
as they can now be fully precomputed. The computation of $v'_i$ now only requires two
operations, since $a_i = -1$ simply changes the sign. The backward substitution
now consists of one subtraction and one division operation, so the total amount of
flops for the tailored algorithm is
\begin{align}
  4(n-1)
\end{align}
This should therefore cut the running time of the algorithm approximately in half.
\subsubsection{The LU decomposition method}
Compared to the Thomas algorithm, the LU decomposition requires a much larger
amount of flops. Where the Thomas neatly avoids dealing with all the $\sim (n^2 - 3n)$
zeros, the LU algorithm consideres every element in every row of the matrix. It is
possible to show that the number of flops for this method is in the order $\frac{2}{3}N^3$.

\subsection{Analytic solution for a specific problem}
In this paper the following special case of the Poisson equation is examined:
\begin{align}
  - \frac{d^2 u}{dx^2} = 100 e^{-10x}
\end{align}
where $0 < x < 1$ and $u(0) = u(1) = 0$, i.e. Dirchelet boundaries. An analytic
solution is obtained by integrating with respect to $x$ twice
\begin{align*}
  u(x) = -e^{-10x} + A + Bx
\end{align*}
Imposing the boundary condition $x(0) = 0$ gives $u(0) = 0 = -1 + A$, so
$A = 1$. Applying $x(1) = 0$ gives $0 = -e^{-10} + 1 + B$, so $B = e^{-10} - 1$.
Inserting the integration constants returns the analytical solution
\begin{align}
  u(x) = 1 - (1 - e^{-10})x - e^{-10x}
\end{align}
where $0 < x < 1$ and $u(0) = u(1) = 0$.

\section{Method}
The algorithms were implemented in C++ and Julia, with the purpose of
learning multiple programming languages and verifying that the implementations were correct.
The source code is available in the attatched GIT-repository. The calculations
were performed several times, and for each method the algorithm times were averaged to produce an
average time. The implementations are explained and listed in the following paragraphs with pseudocode.
The analysis of the solutions and errors was done in Python.

\subsection{The general Thomas algorithm}
The general Thomas algorithm consists of the forward and backward substitutions
examined in the theory section. In pseudocode the loop was implemented as
\begin{lstlisting}[language=cpp, caption={Thomas algorithm implementation for a general tridiagonal matrix}]
b_prime[0] = b[0];
v_prime[0] = v[0];

// Forward substitution
for(i = 1; i <= n-1; i++)
    b_prime[i] = b[i] - (a[i]/b_prime[i-1])*c[i-1];
    v_prime[i] = v[i] - (a[i]/b_prime[i-1])*v_prime[i-1];
}
// Backward substitution
for(i = n-2; i >= 1; i--){
    u[i] = (v_prime[i] - c[i]*u[i+1])/b_prime[i];
}
\end{lstlisting}
\subsection{The optimized algorithm}
Because of the fact that the matrix examined in this paper is both tridiagonal and
symmetric, further optimizations to the algorithm can be made. Since $a_i = c_i = -1$
and $b'_i = (i+1)/i$ can be precomputed, the algorithm simplifies to
\begin{lstlisting}[language=cpp, caption={Optimized version of Thomas algorithm for a symmetric tridiagonal matrix}]
// b_prime is now precomputed
for(i = 1; i <= n-1; i++)
    b_prime[i] = (i+1)/i;

v_prime[0] = v[0];

// Forward substitution
for(i = 1; i <= n-1; i++)
    v_prime[i] = v[i] + (v_prime[i-1]/b_prime[i-1]);
}
// Backward substitution
for(i = n-2; i >= 1; i--){
    u[i] = (v_prime[i] + u[i+1])/b_prime[i];
}
\end{lstlisting}
\subsection{The LU-decomposition}
Solving the matrix equation using the LU-decomposition method was done with
functions from the Armadillo C++ Linear Algebra Library. First, the tridiagonal
matrix A is implemented, and then the Armadillo functions \texttt{lu()} and \texttt{solve()}
are used to solve the two factored matrix equations. In pseudocode, the implementation is
\begin{lstlisting}[language=cpp, caption={Pseudocode of LU-decomposition method implementation}]
#include <armadillo>

for (row = 0; row < size-1; row++){
    A(row, row) = 2;
    if (row > 0)
        A(row, row-1) = -1;
    if (row < size-1)
        A(row, row+1) = -1;

lu(L,U,A);
y = solve(L, btilde);
u = solve(U, y);
\end{lstlisting}
\subsection{Error analysis}
The relative error of the numerical solution at $x_i$ is given by
\begin{align*}
  \epsilon_i = \left| \frac{v_i - u_i}{u_i} \right|
\end{align*}
where $v_i$ is the numerically calculated value and $u_i$ is the analytic value.
The implementation of the analytic solution is rather straightforward. For several
$n$ the errors $\epsilon_i$ are calculated using the above formula, and the
maximum error $\epsilon_\text{n,max}$ is extracted, saved and later plotted against $n$.
For obvious reasons, for these calculations the optimized version of the Thomas algorithm was used.

\subsection{Timing of the Algorithms}
\label{sec:timingmethod}
In order to get an accurate timing of the algoritms, each computation was
repeated \(10^6\) times where this was practical. For the general and special
algorithms, this limit was at matrices of size \(10^4\). For matrices of size \(10^{5-6}\) 

\section{Results and discussion}
\subsection{Solution using the algorithms}
Plot osv.
\subsection{Error and error analysis}
Plot av feil for mange $n$.
\subsection{Timing the algorithms}
The time usage of the algorithms

\sisetup{
  % table-number-alignment = center,
  table-figures-integer  = 1,
  table-figures-decimal  = 2,
  table-figures-exponent = 1,
}
\begin{table}[h]
  \centering
  \begin{tabular}{SSSS}
    {\multirow{2}{*}{N}} & \multicolumn{3}{c}{Time usage [\(s\)]}\\
                                      & {General} & {Special} & {LU} \\
    \(10^{1}\) & 1.592e-7 & & 1.378e-5\\
    \(10^{2}\) & 1.683e-6 & & 9.837e-4\\
    \(10^{3}\) & 1.687e-5 & & 6.214e-1\\
    \(10^{4}\) & 1.682e-4 & & {-} \\
    \(10^{5}\) & 1.734e-5 & & {-} \\
  \end{tabular}
  \caption{Time usage of each algorithm}
  \label{tab:timing}
\end{table}

\section{Conclusion}

\section{References}

\newpage
% \begin{appendices}
\appendix
\section{Appendix}
\subsection{Second derivative}
In section 2 we introduced a approximated expression for the second derivative. To derive this expression, consider a general Taylor expansion
\begin{align*}
f(x) = \sum_{n = 0}^{\infty}\frac{f^{n}(a)}{n!}(x-a)^{n}
\end{align*}
Let $u(x)$ be real valued function and $x\in \mathbb{R}$. We will now expand the function $u(x+h)$ and $u(x-h)$ around $a = x$
to third order
\begin{align*}
u(x+h) \approx u(x)  + \dv{u}{x}h + \dv[2]{u}{x}\frac{h^2}{2!} + \dv[3]{u}{x}\frac{h^3}{3!} + \mathbb{O}(h^4)
\\
u(x-h) \approx u(x) - \dv{u}{x}h + \dv[2]{u}{x}\frac{h^2}{2!} - \dv[3]{u}{x}\frac{h^3}{3!} + \mathbb{O}(h^4)
\end{align*}
Notice, the reason why $u(x-h)$ and $u(x+h)$ was expanded to third order is because the third derivatives cancel each other out, and therefore the error must lie around the fourth term expansion. Now add $u(x-h)$ to $u(x+h)$
\begin{align*}
u(x+h) + u(x-h) \approx 2u(x) + \dv[2]{u}{x}h^2 + 2\mathbb{O}(h^4)
\end{align*}
Taking the $2$ inside $\mathbb{O}(h^4)$ and solving it for $\dv[2]{u}{x}$
\begin{align*}
\dv[2]{u}{x} \approx \frac{u(x+h) + u(x-h) - 2u(x)}{h^2} + \mathbb{O}(h^2)
\end{align*}
note that $\frac{\mathbb{O}(h^4)}{h^2} = \mathbb{O}(h^2)$. If we let \(h \to 0\)
we will get an exact expression for the second derivative.
\begin{align*}
  \dv[2]{u}{x} = \lim_{h \to 0} \frac{u(x+h) + u(x-h) - 2u(x))}{h^{2}} + \mathbb{O}(h^{2})
\end{align*}
\subsection{Deriving a general expression for the diagonal elements after forward substituting}
The general expression for the diagonal elements in $A$ after forward substituting was
\begin{align*}
  b'_i = b_i - \frac{a_i}{b'_{i-1} c_i}
\end{align*}
for $i = 2, \hdots, n$. Since $a_i = c_i$ for all $i$ in the special case examined in this paper,
 the expression for $b'_i$ simplifies to
\begin{align*}
  b'_i = b_i - \frac{1}{b'_{i-1}}
\end{align*}
In an attempt at further simplify the expression, a few iterations are calculated, and
a pattern seems to emerge:
\begin{align*}
  b'_1 &= b_1 = 2\\
  b'_2 &= b_2 - \frac{1}{b'_1} = 2 - \frac{1}{2} = \frac{3}{2}\\
  b'_3 &= b_3 - \frac{1}{b'_2} = 2 - \frac{2}{3} = \frac{4}{3}\\
  b'_4 &= b_4 - \frac{1}{b'_3} = 2 - \frac{3}{4} = \frac{5}{4}
\end{align*}
By inspection, $b'_i$ seems to follow the pattern
\begin{align*}
  b'_i &= \frac{i+1}{i}
\end{align*}
which is assumed valid for $i = 1,2,\hdots,n$. A proof by induction is used to
show that the formula is indeed correct for all $i \geq 1$.
\\[12pt]
For any integer $i \geq 1$, let $S(i)$ denote the statement
\begin{align*}
  S(i): b'_i = 2 - \frac{1}{b'_{i-1}} = \frac{i+1}{i}
\end{align*}
where we have defined $b'_{1} = 2$.
\\[12pt]
In the case $i = 1$, $S(1)$ is obviously true because $b'_1$ is defined as $b'_1 = b_i = 2$.
Now, for some fixed $j \geq 1$, assume that $S(j)$ holds. Then, $b_{j+1}$ is given by
\begin{align*}
  b'_{j+1} = 2 - \frac{1}{b'_j}
\end{align*}
But since $S(j)$ holds, $b'_j = \frac{j+1}{j}$, and
\begin{align*}
  b'_{j+1} = 2 - \frac{j}{j+1} = \frac{j+2}{j+1} = \frac{(j+1) + 1}{(j+1)}
\end{align*}
which proves $S(i)$ is true for all $i \geq 1$.
% \end{appendices}
\end{document}
